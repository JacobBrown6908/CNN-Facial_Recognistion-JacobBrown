[
  {
    "objectID": "posts/Week 9/index.html",
    "href": "posts/Week 9/index.html",
    "title": "Week 8",
    "section": "",
    "text": "Weekly Work Update\nThis week, I’ve been working on building a blind holdout set to test my model against new pictures it hasn’t seen before. I’ve also been preparing a poster board for the BYU-Idaho Intellectual Conference. I plan to include a QR code that links to a Streamlit app showcasing my blog, Google Colab projects, and my overall work.\n\nHoldout Set\nTo minimize the possibility of my model encountering familiar images, I’ve decided to use only photos of celebrities from 2025. Since the dataset was created before 2025, this ensures the model is tested on truly unseen data.\n\n\nStreamlit\nAs I build my Streamlit app, I’m starting from scratch and learning along the way. Streamlit is more intuitive and user-friendly than I expected. The coding is relatively straightforward, with intuitive functions, yet the possibilities are vast. I plan to explore various Streamlit projects to gather ideas and inspiration for my own work."
  },
  {
    "objectID": "posts/Week 7/index.html",
    "href": "posts/Week 7/index.html",
    "title": "Week 7",
    "section": "",
    "text": "Weekly Work\nThis week, I mainly focused on job applications, but I also spent some time working on my model. I reverted to my original model size, reducing the 128-layer from my model that we discussed a few weeks ago. I saved my weights and am now trying to recover the scores I achieved a few weeks ago, which were around 80% accuracy.\nAdditionally, I have been working on a side project within my society. We are building a CNN that analyzes 2D slices of a 3D MRI model of the elbow. Our goal is to detect whether the elbow is injured, and then, if possible, identify cases of PTJC (Post-Traumatic Joint Contracture). PTJC is a condition that affects multiple joints, is unpredictable, and can develop after a joint-related injury. We hope to identify elbows that exhibit signs of PTJC.\nFor this project, we are using supervised learning to determine whether an elbow is injured and unsupervised learning to detect PTJC. We are also developing an application in Streamlit that will allow users to upload MRI scans. The app will process the scans, extract slices, and determine if the elbow is injured."
  },
  {
    "objectID": "posts/Week 5/index.html",
    "href": "posts/Week 5/index.html",
    "title": "Week 5",
    "section": "",
    "text": "Weekly Work\nThis week, I worked on improving my code to achieve a better validation loss and validation accuracy. I am currently at around 80% accuracy and validation accuracy, with a validation loss between 0.3 and 0.4. However, I wanted to refine these numbers further, so I added a piece of code that dynamically adjusts the learning rate. If the validation loss gets stuck for more than three epochs, the learning rate decreases by 50%, with a minimum value of 1e-8. I am continuing to improve this model and aiming to exceed 90% accuracy.\n\n\nCode\nHere is the learning rate scheduler I implemented:\n# Define learning rate scheduler\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_loss',  # Reduce LR based on validation loss\n    factor=0.5,          # Reduce LR by 50% when no improvement\n    patience=3,          # Wait 3 epochs before reducing LR\n    min_lr=1e-8          # Minimum allowed learning rate\n)\nThis adjustment has improved my model, bringing me closer to my goal of 90% accuracy. Additionally, I added another dense layer and dropout to further enhance model performance:\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dropout(0.4),\n  tf.keras.layers.Dense(512, activation=tf.keras.layers.LeakyReLU()),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(256, activation=tf.keras.layers.LeakyReLU()),\n  # tf.keras.layers.Dropout(0.2), # remove when using drop out 26\n  # tf.keras.layers.Dense(128, activation=tf.keras.layers.LeakyReLU()), # remove when using drop out 26\n  tf.keras.layers.Dense(17, activation='softmax')"
  },
  {
    "objectID": "posts/Week 3/index.html",
    "href": "posts/Week 3/index.html",
    "title": "Week 3",
    "section": "",
    "text": "This is my 3rd week of building my model for a facial recognition software. This week, I spent most of the time working on my resume with a Quarto building tool we have been developing. I have been trying to learn how Docker works, but this is something I don’t fully understand, and research has not helped me to reopen my container. However, I hope that I can continue to build up my resume and work on getting it on one page.\nI also worked on transitioning my code to Google Colab so I can save my weights and work on building my model from where I left off. This came with a handful of problems that I was not expecting to encounter. First, I needed to learn more about a new library that helps to connect to my Google Drive. Second, I needed to add a new folder and understand how paths work in Google Drive compared to my local memory. Lastly, I needed to learn how to call weights and where to put code to save weights.\nThis week felt like when I solved one of these issues, I ran into another issue, but I eventually got the code to work, and now I am able to save and call my weights on my Drive.\nHere are a few snippets of code that I was working on this week regarding my code:\ncheckpoint_path = \"/content/drive/My Drive/Senior_Project/check_points/checkpoint_13.weights.h5\"\n\nif os.path.exists(checkpoint_path):\n    print(\"Loading saved weights...\")\n    model.load_weights(checkpoint_path)\nelse:\n    print(\"No saved weights found, training from scratch.\")\ncheckpoint_dir = \"/content/drive/MyDrive/Senior_Project/check_points\"\ncheckpoint_path = os.path.join(checkpoint_dir, \"checkpoint_{epoch:02d}.weights.h5\")  # Save weights\n\n# Ensure the checkpoint directory exists\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\n\n# Define model checkpoint callback\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=os.path.join(checkpoint_dir, \"checkpoint_{epoch:02d}.weights.h5\"),\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True\n)"
  },
  {
    "objectID": "posts/Week 11/index.html",
    "href": "posts/Week 11/index.html",
    "title": "Week 8",
    "section": "",
    "text": "Weekly Work Update\nThis week, I was working on job applications and informational interviews. I had an informational interview with a family friend who works for Lockheed Martin at Hill Air Force Base. This is a location where I would like to work, so I was able to connect with her and talk about what she does in software engineering. I also asked her for contacts with others in her field.\nThen, I started working on a website for my poster board. I want to build a Streamlit website to put a QR code on my board and improve the quality of the poster board."
  },
  {
    "objectID": "posts/Week 1/index.html",
    "href": "posts/Week 1/index.html",
    "title": "Week 1",
    "section": "",
    "text": "This is an introduction to my facial recognition software that I am building.\nFirst, I started by doing some research on different machine learning models that would be better to use when building this software. Some of the insights I gained were on a CNN (Convolutional Neural Network).\n\nPros\nLearns from raw pixel data. Most smartphones use a CNN for their facial identification software, making it transferable to a smart device.\n\n\nCons\nEasy to overfit the data. Requires large amounts of training data to be effective. Demands significant computing power to train on lots of data. So, I started to look into alternative ML models and was pointed to a few:\n-RNNs\n-CapsNets\n-GANs\nRNNs are mainly used for dynamic inputs, such as video.\nCapsNets are better at handling multiple overlapping objects, making it easier when dealing with different images at various angles with more variation in each photo.\nLastly, GANs are better for image recognition when dealing with augmentation, differing brightness, rotation, zoom, enhancements, and manipulations."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About the Project:\nThis was a personal idea I had:\nI wanted to create a machine learning model that could quickly and accurately identify a face so that I could use it in an application with an identification aspect.\nMy process is as follows:\nFirst, I am building a model that can correctly identify a face without having seen the picture before. Next, I plan to build code that attaches to an application on a smartphone or another smart device."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science blog project",
    "section": "",
    "text": "Week 8\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 23, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 8\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 16, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 8\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 9, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 8\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 2, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 7\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 23, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 6\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 16, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 5\n\n\n\n\n\n\nnews\n\n\ncode\n\n\n\n\n\n\n\n\n\nFeb 9, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 4\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 2, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3\n\n\n\n\n\n\nnews\n\n\ncode\n\n\n\n\n\n\n\n\n\nJan 29, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\n\n\n\n\n\n\nnews\n\n\ncode\n\n\n\n\n\n\n\n\n\nJan 19, 2025\n\n\nJacob Brown\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 1\n\n\n\n\n\n\nnews\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 12, 2025\n\n\nJacob Brown\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Week 10/index.html",
    "href": "posts/Week 10/index.html",
    "title": "Week 8",
    "section": "",
    "text": "Weekly Work Update\nAs I have been working with streamlit I have found it hard to stick with just using Streamlit cloud, so I am trying to intigreate my code into docker, becaseu I want this webpage to be priviate and not on the cloud. But as I have been looking at code in streamlit I found one pice that I realy like."
  },
  {
    "objectID": "posts/Week 2/index.html",
    "href": "posts/Week 2/index.html",
    "title": "Week 2",
    "section": "",
    "text": "This week, I began gathering data and working on the code for my project. I found a dataset containing pictures of 17 celebrities, with 100 different pictures of each, resulting in 1,700 total images of famous people. I started writing code to process this dataset. Specifically, I created a script that would dynamically pull the names of the folders (each corresponding to a person in the dataset) to identify the celebrities. This approach allows for adding more folders and individuals to the dataset without modifying the code, as long as the folder names match the individuals they represent.\nHere’s the code I wrote to generate the target names dynamically:\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npath=\"C:/Users/brown/OneDrive/Documents/Senior project/data/Celebrity Faces Dataset\"\ntarget_names = os.listdir(path)\ntarget_names\nIn the process, I learned about the os library, which interacts directly with the operating system. This library allowed me to retrieve the names of folders and files easily.\n\nData Augmentation\nAfter setting up the dataset, I implemented augmentations to increase image variations, which helps the model generalize better. I made sure that both the training and testing images had the same augmentations by creating a dynamic function. This approach ensured consistency and reduced the likelihood of user error.\n\n\nNeural Network\nNext, I started building the neural network. During training, I encountered a significant issue: overfitting. Each image in the dataset was different, so the model struggled to generalize. Additionally, the dataset size was relatively small for training a neural network.\nTo address this, I made the neural network larger, which helped reduce overfitting. This adjustment improved accuracy and reduced loss, while also increasing validation accuracy and lowering validation loss. However, the validation metrics still showed a large gap: the validation accuracy was around 0.4, and the validation loss was approximately 2.7.\n\n\nPlan for Next Week\nTo further tackle the overfitting issue, I plan to increase the dataset size by duplicating all images three times for each person. This would result in 300 images per person, with each of the 100 original images repeating three times. My goal is to give the model more data to train on, including some similar images, after applying augmentations."
  },
  {
    "objectID": "posts/Week 4/index.html",
    "href": "posts/Week 4/index.html",
    "title": "Week 4",
    "section": "",
    "text": "This week, I primarily focused on refining my resume, both independently and as part of our classwork. We have been exploring the use of a new GitHub repository to create QMD templates specifically designed for Data Science resumes. This has been a valuable experience, as it not only helped me improve my resume but also deepened my understanding of how to structure professional documents using QMD. I feel that dedicating time to this project was a great investment in my career development.\nIn addition to working on my resume, I have been actively applying for jobs and participating in interviews. I recently had three interviews with the Idaho National Laboratory (INL) through the SULI program. These interviews have been an insightful experience, allowing me to refine my interview skills and gain a better understanding of the hiring process in my field. The process of preparing, interviewing, and revising my resume based on feedback has been incredibly beneficial.\nAs a result of this week’s work, I will be attaching a finalized version of my resume, which reflects the improvements and insights I have gained throughout this process."
  },
  {
    "objectID": "posts/Week 6/index.html",
    "href": "posts/Week 6/index.html",
    "title": "Week 6",
    "section": "",
    "text": "Weekly Work\nThis week, I was mainly working on finalizing my resume and preparing for job/internship interviews, specifically in AI development or machine learning research. I was able to attend a job fair and set up interviews with a few companies. I also spent some time working on and improving my CNN model. I worked with the larger model that I mentioned last week, but the best accuracy I achieved was around 60%, with a validation loss of about 0.5. Since this was not quite where I wanted my model to be, I decided to switch back at the end of the week.\n\n\nReLU vs LeakyReLU\nI also did some research into my model, specifically on activation functions in the neural network section after flattening the images. I looked into LeakyReLU, which is a variation of the ReLU function. One key difference is that when a negative input is given, ReLU returns a 0, whereas LeakyReLU returns a small negative value. This helps prevent neurons from “dying” and improves data flow. LeakyReLU is particularly useful for deeper networks like CNNs, whereas standard ReLU is better suited for general machine learning applications."
  },
  {
    "objectID": "posts/Week 8/index.html",
    "href": "posts/Week 8/index.html",
    "title": "Week 8",
    "section": "",
    "text": "Weekly Work Update\nThis week, I was working on job applications and informational interviews. I had an informational interview with a family friend who works for Lockheed Martin at Hill Air Force Base. This is a location where I would like to work, so I was able to connect with her and talk about what she does in software engineering. I also asked her for contacts with others in her field.\nThen, I started working on a website for my poster board. I want to build a Streamlit website to put a QR code on my board and improve the quality of the poster board."
  }
]